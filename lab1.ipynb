{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bnXz3TepRZ1H"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "api_token = {\"username\":\"iobananaoi\",\"key\":\"0cbdda23beeb18cbb57e9e88bf26bfd1\"}\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import ToTensor, Compose, Normalize\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kaggle\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import PIL\n",
        "from itertools import groupby"
      ],
      "metadata": {
        "id": "IQvh9uxiRbsS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d romanleo2003/labtinkoff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_swliWXqMnJ",
        "outputId": "efdd03ef-8e8b-4129-f0c5-7c48e8651458"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading labtinkoff.zip to /content\n",
            "100% 2.12G/2.13G [01:35<00:00, 24.9MB/s]\n",
            "100% 2.13G/2.13G [01:35<00:00, 23.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/labtinkoff.zip\", 'r')\n",
        "zip_ref.extractall()"
      ],
      "metadata": {
        "id": "k2u7aA9sqnPE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in zip_ref.namelist():  \n",
        "    old_name = \"/content/\" + name\n",
        "    new_name = name.encode(\"cp437\").decode('utf-8')\n",
        "\n",
        "    zip_ref.extract(name) \n",
        "    os.rename(name, new_name) "
      ],
      "metadata": {
        "id": "0OAAFDU_qouG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "b4O5NY9J7OGH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0336733f-0c99-4009-d956-db28ac04ef84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "metadata": {
        "id": "iO9-SKLNWx37"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "wHhzR30xRij6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CCPD(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_pathes = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))][:64000]\n",
        "        self.img_labels = [label.split(\"-\")[1][:-4] for label in self.img_pathes][:64000]\n",
        "        self.img_dir = img_dir \n",
        "        self.transform = transform \n",
        "\n",
        "        self.unique_symbols = set([s for label in self.img_labels for s in label])\n",
        "        self.symb2idx = {list(self.unique_symbols)[i]: i+1 for i in range(len(self.unique_symbols))}\n",
        "        self.idx2symb = {i+1: list(self.unique_symbols)[i] for i in range(len(self.unique_symbols))}\n",
        "        \n",
        "    def convert_label2idxs(self, label: str) -> list:\n",
        "        return [self.symb2idx[symb] for symb in label]\n",
        "    \n",
        "    def convert_idxs2label(self, idxs: list) -> str:\n",
        "        symbs_list = [self.idx2symb[idx.item()] for idx in idxs]\n",
        "        return reduce(lambda x, y: x + y, symbs_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_pathes[idx])\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
        "        image = cv2.resize(image, (100, 40))\n",
        "        label = torch.tensor(self.convert_label2idxs(self.img_labels[idx]))\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label"
      ],
      "metadata": {
        "id": "viHHZ-BwRktg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CCPD(\"CCPD2019-dl1/train\", transform=ToTensor())\n",
        "test_data = CCPD(\"CCPD2019-dl1/test\", transform=ToTensor())"
      ],
      "metadata": {
        "id": "nbW0Swd0RnHj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "mRI_6LAgRoaN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_features, example_labels = next(iter(train_dataloader))\n",
        "img = example_features[0].squeeze()\n",
        "label = example_labels[0]\n",
        "print(f\"Features shape: {example_features.shape}\")\n",
        "print(train_data.convert_idxs2label(label))\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q7WYEvgJRpkK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "498ce3ef-763b-4386-90f5-7c1adb454a46"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: torch.Size([64, 1, 40, 100])\n",
            "皖AN6360\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model structure"
      ],
      "metadata": {
        "id": "gy0xvCFrRrxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(nn.Conv2d(1, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
        "            nn.PReLU(), nn.MaxPool2d(kernel_size=2, stride=1)) \n",
        "        self.layer2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),  \n",
        "            nn.PReLU(), nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer3 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1), \n",
        "            nn.PReLU(), nn.MaxPool2d(kernel_size=2, stride=1))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer4 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=2), \n",
        "            nn.PReLU(), nn.MaxPool2d(kernel_size=2, stride=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layer3(x)\n",
        "        #x = self.layer4(x)\n",
        "\n",
        "        x = x.reshape(x.shape[0], -1, x.shape[2]*x.shape[3])\n",
        "        \n",
        "        return x\n",
        "     "
      ],
      "metadata": {
        "id": "JdWdm2TbTuU7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dims, num_classes, num_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.lstm = nn.GRU(latent_dims, latent_dims, num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(latent_dims, num_classes)\n",
        "        self.sm = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, state = self.lstm(x)\n",
        "        logits = self.fc(out)\n",
        "        preds = self.sm(logits)\n",
        "\n",
        "        return preds"
      ],
      "metadata": {
        "id": "nMyCXt06X1KZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CRNN(nn.Module):\n",
        "    def __init__(self, latent_dims, batch_size, num_classes, rnn_layers=3, rnn_dropout=0.01, cnn_dropout=0.01):\n",
        "        super(CRNN, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(cnn_dropout)\n",
        "        self.decoder = Decoder(latent_dims, num_classes, rnn_layers, rnn_dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vlzCyD0ERsSY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training part"
      ],
      "metadata": {
        "id": "MVx7Fw51dWY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_data.unique_symbols) + 1 # Reserve one more for blank symbol"
      ],
      "metadata": {
        "id": "Jh8iN8pBUTmO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    for i, (img, label) in enumerate(dataloader):\n",
        "        img, label = img.to(device), label.to(device)\n",
        "\n",
        "        # Pred computation\n",
        "        pred = model(img)\n",
        "        pred = pred.permute(1, 0, 2)\n",
        "        \n",
        "        ctc_loss = nn.CTCLoss(reduction='mean', zero_infinity=True)\n",
        "        input_lengths = torch.IntTensor(batch_size).fill_(23)\n",
        "        target_lengths = torch.full(size=(batch_size,), fill_value=7, dtype=torch.long)\n",
        "        loss = ctc_loss(pred, label, input_lengths, target_lengths)\n",
        "\n",
        "        #Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            loss, current = loss.item(), i * len(img)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "cQ7jXvJl5LHT"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CRNN(931, batch_size, num_classes, rnn_layers=2, rnn_dropout=0.25, cnn_dropout=0.25).to(device)"
      ],
      "metadata": {
        "id": "gI2p_5MpvAeQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"========== Epoch {i+1}: ==========\")\n",
        "    train(model, train_dataloader, optimizer)"
      ],
      "metadata": {
        "id": "qvIOC1V2jhv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfafec25-30bb-4cbb-e37e-02cb267bc484"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Epoch 1: ==========\n",
            "loss: -2.670928  [    0/64000]\n",
            "loss: -2.648199  [ 6400/64000]\n",
            "loss: -2.665310  [12800/64000]\n",
            "loss: -2.665378  [19200/64000]\n",
            "loss: -2.661032  [25600/64000]\n",
            "loss: -2.655488  [32000/64000]\n",
            "loss: -2.654016  [38400/64000]\n",
            "loss: -2.662504  [44800/64000]\n",
            "loss: -2.652750  [51200/64000]\n",
            "loss: -2.653880  [57600/64000]\n",
            "========== Epoch 2: ==========\n",
            "loss: -2.645248  [    0/64000]\n",
            "loss: -2.648199  [ 6400/64000]\n",
            "loss: -2.665310  [12800/64000]\n",
            "loss: -2.665378  [19200/64000]\n",
            "loss: -2.661032  [25600/64000]\n",
            "loss: -2.655488  [32000/64000]\n",
            "loss: -2.654016  [38400/64000]\n",
            "loss: -2.662504  [44800/64000]\n",
            "loss: -2.652750  [51200/64000]\n",
            "loss: -2.653880  [57600/64000]\n",
            "========== Epoch 3: ==========\n",
            "loss: -2.645248  [    0/64000]\n",
            "loss: -2.648199  [ 6400/64000]\n",
            "loss: -2.665310  [12800/64000]\n",
            "loss: -2.665378  [19200/64000]\n",
            "loss: -2.661032  [25600/64000]\n",
            "loss: -2.655488  [32000/64000]\n",
            "loss: -2.654016  [38400/64000]\n",
            "loss: -2.662504  [44800/64000]\n",
            "loss: -2.652750  [51200/64000]\n",
            "loss: -2.653880  [57600/64000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing part"
      ],
      "metadata": {
        "id": "TfvuxEhAB7YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    num_batches = batch_size\n",
        "\n",
        "    test_loss, correct = 0, 0\n",
        "    i = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            if i == 156:\n",
        "                break\n",
        "            i += 1\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            pred = pred.permute(1, 0, 2)\n",
        "\n",
        "            ctc_loss = nn.CTCLoss(zero_infinity=True)\n",
        "            input_lengths = torch.IntTensor(batch_size).fill_(23)\n",
        "            target_lengths = torch.full(size=(batch_size,), fill_value=7, dtype=torch.long)\n",
        "            test_loss += ctc_loss(pred, y, input_lengths, target_lengths).item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "i8zUdiS4WZfZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s6016hNYt7g",
        "outputId": "c0a46bd2-5d0a-4b2a-8667-afdad18dc0ac"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg loss: -6.471286 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На лицо очевидное недообучение модели. Скорее всего проблема в реализации выбранной архитектуры.\n",
        "Из идей, как можно было бы привести её к удобоваримому виду: <br>\n",
        "1) Заменить GRU, на LSTM(bidirectional=true), требует больше времени для обучения, но работает лучше<br>\n",
        "2) Добавить эпох<br>\n",
        "3) Как-то поменять decoder, добавить нормализацию по батчу, добавить больше конволюционных слоёв, увеличить окно ядра<br>\n",
        "4) Добавить слоёв в LSTM"
      ],
      "metadata": {
        "id": "AYKTNTrJ7Xwz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1yCtQrkbLGQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}